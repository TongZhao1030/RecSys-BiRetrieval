"""
è›‹ç™½è´¨-åˆ†å­åŒå‘æ£€ç´¢ Demo
Gradio Web UI

åŸºäº IC50 è®­ç»ƒçš„åŒå¡”å¯¹æ¯”å­¦ä¹ æ¨¡å‹
æ”¯æŒ:
- Protein â†’ Molecule: ç»™å®šé¶ç‚¹è›‹ç™½ï¼Œæ£€ç´¢å€™é€‰ç»“åˆåˆ†å­
- Molecule â†’ Protein: ç»™å®šå°åˆ†å­ï¼Œè¯†åˆ«æ½œåœ¨é¶ç‚¹è›‹ç™½
- ç›¸ä¼¼åº¦è®¡ç®—: è¯„ä¼°è›‹ç™½è´¨-åˆ†å­é…å¯¹çš„ç»“åˆå¯èƒ½æ€§
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
import gradio as gr
from transformers import AutoModel, AutoTokenizer
from datasets import load_from_disk
from collections import defaultdict

# ============================================================================
# é…ç½®
# ============================================================================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
PATH_MODEL = "./outputs/model_best.pth"
PATH_SAPROT = "./models/SaProt_650M_AF2"
PATH_CHEMBERTA = "./models/ChemBERTa-zinc-base-v1"
PATH_DATA = "./data/vladak_bindingdb/test"
TOP_K = 10
POSITIVE_THRESHOLD = 7.0  # ä¸è®­ç»ƒä¸€è‡´

# æ•°æ®åº“å¤§å°é™åˆ¶
MAX_PROTEINS = 1000
MAX_MOLECULES = 3000

# ============================================================================
# æ¨¡å‹å®šä¹‰ (ä¸è®­ç»ƒè„šæœ¬ä¸€è‡´)
# ============================================================================
class DualTowerModel(nn.Module):
    def __init__(self, path_saprot, path_chemberta):
        super().__init__()
        self.prot_model = AutoModel.from_pretrained(path_saprot, trust_remote_code=True)
        self.mol_model = AutoModel.from_pretrained(path_chemberta)
        
        prot_hidden = self.prot_model.config.hidden_size
        mol_hidden = 768
        hidden_dim = 1024
        embedding_dim = 256
        
        self.prot_proj = nn.Sequential(
            nn.Linear(prot_hidden, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.LayerNorm(hidden_dim//2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim//2, embedding_dim)
        )
        
        self.mol_proj = nn.Sequential(
            nn.Linear(mol_hidden, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.LayerNorm(hidden_dim//2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim//2, embedding_dim)
        )
        
        self.log_temperature = nn.Parameter(torch.tensor(math.log(0.07)))
    
    def encode_protein(self, input_ids, attention_mask):
        outputs = self.prot_model(input_ids=input_ids, attention_mask=attention_mask)
        mask = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).float()
        embeddings = torch.sum(outputs.last_hidden_state * mask, dim=1) / torch.clamp(mask.sum(1), min=1e-9)
        embeddings = self.prot_proj(embeddings)
        embeddings = F.normalize(embeddings, p=2, dim=1)
        return embeddings
    
    def encode_molecule(self, input_ids, attention_mask):
        outputs = self.mol_model(input_ids=input_ids, attention_mask=attention_mask)
        mask = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).float()
        embeddings = torch.sum(outputs.last_hidden_state * mask, dim=1) / torch.clamp(mask.sum(1), min=1e-9)
        embeddings = self.mol_proj(embeddings)
        embeddings = F.normalize(embeddings, p=2, dim=1)
        return embeddings
    
    def get_temperature(self):
        return self.log_temperature.exp()

# ============================================================================
# å…¨å±€å˜é‡
# ============================================================================
model = None
mol_tokenizer = None
prot_tokenizer = None
mol_database = []
prot_database = []
mol_vectors = None
prot_vectors = None
pair_pic50 = {}  # (è›‹ç™½è´¨, åˆ†å­) -> pIC50
prot_to_idx = {}  # è›‹ç™½è´¨ -> ç´¢å¼•
mol_to_idx = {}   # åˆ†å­ -> ç´¢å¼•

# ç¤ºä¾‹æ•°æ®ï¼ˆä»æ•°æ®åº“ä¸­é€‰æ‹©ï¼‰
EXAMPLE_PROTEIN = ""
EXAMPLE_SMILES = ""

# ============================================================================
# æ¨¡å‹å’Œæ•°æ®åŠ è½½
# ============================================================================
def load_model():
    """åŠ è½½æ¨¡å‹å’Œæ•°æ®"""
    global model, mol_tokenizer, prot_tokenizer
    global mol_database, prot_database, mol_vectors, prot_vectors
    global pair_pic50, prot_to_idx, mol_to_idx
    global EXAMPLE_PROTEIN, EXAMPLE_SMILES
    
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = DualTowerModel(PATH_SAPROT, PATH_CHEMBERTA).to(DEVICE)
    
    checkpoint = torch.load(PATH_MODEL, map_location=DEVICE, weights_only=False)
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    else:
        state_dict = checkpoint
    
    new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
    model.load_state_dict(new_state_dict)
    model.eval()
    
    temp = model.get_temperature().item()
    print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {DEVICE}, æ¸©åº¦å‚æ•°: {temp:.4f}")
    
    mol_tokenizer = AutoTokenizer.from_pretrained(PATH_CHEMBERTA)
    prot_tokenizer = AutoTokenizer.from_pretrained(PATH_SAPROT, trust_remote_code=True)
    
    # ========================================================================
    # æ„å»ºæ•°æ®åº“ï¼šä»¥è›‹ç™½è´¨ä¸ºä¸­å¿ƒï¼Œç¡®ä¿æ­£æ ·æœ¬åˆ†å­åœ¨åº“ä¸­
    # ========================================================================
    print("æ­£åœ¨æ„å»ºæ£€ç´¢æ•°æ®åº“...")
    try:
        dataset = load_from_disk(PATH_DATA)
    except Exception as e:
        print(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        return
    
    # 1. æ”¶é›†æ‰€æœ‰é…å¯¹å…³ç³»
    print("æ”¶é›†é…å¯¹å…³ç³»...")
    prot_to_mols = defaultdict(list)  # prot -> [(mol, pic50), ...]
    mol_to_prots = defaultdict(list)  # mol -> [(prot, pic50), ...]
    all_pairs = []
    
    for idx in range(len(dataset)):
        try:
            prot = dataset[idx]['protein']
            mol = dataset[idx]['ligand']
            pic50 = dataset[idx].get('ic50', None)
            
            if pic50 is None or math.isnan(pic50) or math.isinf(pic50):
                continue
            if pic50 < -2 or pic50 > 14:
                continue
            
            prot_to_mols[prot].append((mol, pic50))
            mol_to_prots[mol].append((prot, pic50))
            all_pairs.append((prot, mol, pic50))
            
        except Exception as e:
            continue
    
    print(f"åŸå§‹æ•°æ®: {len(all_pairs)} é…å¯¹, {len(prot_to_mols)} è›‹ç™½è´¨, {len(mol_to_prots)} åˆ†å­")
    
    # 2. é€‰æ‹©æœ‰æ­£æ ·æœ¬çš„è›‹ç™½è´¨ï¼ŒæŒ‰æ­£æ ·æœ¬æ•°æ’åº
    prots_with_positives = []
    for prot, mols in prot_to_mols.items():
        positives = [(m, p) for m, p in mols if p >= POSITIVE_THRESHOLD]
        if len(positives) >= 2:  # è‡³å°‘æœ‰2ä¸ªæ­£æ ·æœ¬çš„è›‹ç™½è´¨
            prots_with_positives.append((prot, len(positives), mols))
    
    # æŒ‰æ­£æ ·æœ¬æ•°é™åºæ’åº
    prots_with_positives.sort(key=lambda x: -x[1])
    print(f"æœ‰>=2ä¸ªæ­£æ ·æœ¬çš„è›‹ç™½è´¨æ•°: {len(prots_with_positives)}")
    
    # 3. é€‰æ‹©è›‹ç™½è´¨ï¼Œå¹¶ç¡®ä¿å…¶æ­£æ ·æœ¬åˆ†å­éƒ½åœ¨åˆ†å­åº“ä¸­
    selected_prots = set()
    selected_mols = set()
    
    for prot, n_pos, mols in prots_with_positives[:MAX_PROTEINS]:
        selected_prots.add(prot)
        # æ·»åŠ è¯¥è›‹ç™½è´¨çš„æ‰€æœ‰æ­£æ ·æœ¬åˆ†å­
        for mol, pic50 in mols:
            if pic50 >= POSITIVE_THRESHOLD:
                selected_mols.add(mol)
    
    print(f"é€‰æ‹©è›‹ç™½è´¨åï¼Œæ­£æ ·æœ¬åˆ†å­æ•°: {len(selected_mols)}")
    
    # 4. è¡¥å……æ›´å¤šåˆ†å­ï¼ˆåŒ…æ‹¬è´Ÿæ ·æœ¬ï¼Œä½¿æ£€ç´¢æ›´æœ‰æŒ‘æˆ˜æ€§ï¼‰
    for prot, n_pos, mols in prots_with_positives[:MAX_PROTEINS]:
        for mol, pic50 in mols:
            selected_mols.add(mol)
            if len(selected_mols) >= MAX_MOLECULES:
                break
        if len(selected_mols) >= MAX_MOLECULES:
            break
    
    # å¦‚æœåˆ†å­æ•°è¿˜ä¸å¤Ÿï¼Œä»å…¶ä»–è›‹ç™½è´¨è¡¥å……
    if len(selected_mols) < MAX_MOLECULES:
        for mol in mol_to_prots.keys():
            if mol not in selected_mols:
                selected_mols.add(mol)
                if len(selected_mols) >= MAX_MOLECULES:
                    break
    
    # 5. æ„å»ºæœ€ç»ˆæ•°æ®åº“
    prot_database = list(selected_prots)
    mol_database = list(selected_mols)
    
    prot_to_idx = {p: i for i, p in enumerate(prot_database)}
    mol_to_idx = {m: i for i, m in enumerate(mol_database)}
    
    # 6. æ„å»ºé…å¯¹æ˜ å°„ï¼ˆåªä¿ç•™åœ¨åº“ä¸­çš„é…å¯¹ï¼‰
    for prot, mol, pic50 in all_pairs:
        if prot in selected_prots and mol in selected_mols:
            key = (prot, mol)
            if key not in pair_pic50 or pic50 > pair_pic50[key]:
                pair_pic50[key] = pic50
    
    # ç»Ÿè®¡
    n_positive_pairs = sum(1 for v in pair_pic50.values() if v >= POSITIVE_THRESHOLD)
    print(f"\næ•°æ®åº“æ„å»ºå®Œæˆ:")
    print(f"  è›‹ç™½è´¨åº“: {len(prot_database)}")
    print(f"  åˆ†å­åº“: {len(mol_database)}")
    print(f"  å·²çŸ¥é…å¯¹æ•°: {len(pair_pic50)} (å…¶ä¸­æ­£æ ·æœ¬: {n_positive_pairs})")
    
    # 7. é€‰æ‹©å¥½çš„ç¤ºä¾‹ï¼ˆæ­£æ ·æœ¬æ•°æœ€å¤šçš„è›‹ç™½è´¨å’Œå®ƒçš„ä¸€ä¸ªæ­£æ ·æœ¬åˆ†å­ï¼‰
    if prots_with_positives:
        best_prot, n_pos, mols = prots_with_positives[0]
        EXAMPLE_PROTEIN = best_prot
        
        # æ‰¾è¯¥è›‹ç™½è´¨ pIC50 æœ€é«˜çš„æ­£æ ·æœ¬åˆ†å­
        best_mol = None
        best_pic50 = 0
        for mol, pic50 in mols:
            if pic50 >= POSITIVE_THRESHOLD and pic50 > best_pic50:
                best_mol = mol
                best_pic50 = pic50
        
        if best_mol:
            EXAMPLE_SMILES = best_mol
            print(f"\nç¤ºä¾‹è›‹ç™½è´¨: {EXAMPLE_PROTEIN[:50]}... (æ­£æ ·æœ¬æ•°: {n_pos})")
            print(f"ç¤ºä¾‹åˆ†å­: {EXAMPLE_SMILES} (pIC50: {best_pic50:.2f})")
    
    # 8. é¢„è®¡ç®—å‘é‡
    print("\næ­£åœ¨é¢„è®¡ç®—å‘é‡...")
    mol_vectors = encode_molecules_batch(mol_database)
    prot_vectors = encode_proteins_batch(prot_database)
    print("å‘é‡è®¡ç®—å®Œæˆ")

def encode_protein(seq):
    """ç¼–ç å•ä¸ªè›‹ç™½è´¨"""
    formatted = " ".join([aa + "#" for aa in seq])
    inputs = prot_tokenizer(formatted, return_tensors="pt", padding=True, 
                            truncation=True, max_length=512).to(DEVICE)
    with torch.no_grad():
        vec = model.encode_protein(inputs['input_ids'], inputs['attention_mask'])
    return vec

def encode_molecule(smiles):
    """ç¼–ç å•ä¸ªåˆ†å­"""
    inputs = mol_tokenizer(smiles, return_tensors="pt", padding=True,
                           truncation=True, max_length=128).to(DEVICE)
    with torch.no_grad():
        vec = model.encode_molecule(inputs['input_ids'], inputs['attention_mask'])
    return vec

def encode_proteins_batch(prot_list, batch_size=8):
    """æ‰¹é‡ç¼–ç è›‹ç™½è´¨"""
    all_vecs = []
    for i in range(0, len(prot_list), batch_size):
        batch = prot_list[i:i+batch_size]
        formatted = [" ".join([aa + "#" for aa in seq]) for seq in batch]
        inputs = prot_tokenizer(formatted, return_tensors="pt", padding=True,
                                truncation=True, max_length=512).to(DEVICE)
        with torch.no_grad():
            vecs = model.encode_protein(inputs['input_ids'], inputs['attention_mask'])
        all_vecs.append(vecs)
    return torch.cat(all_vecs, dim=0)

def encode_molecules_batch(mol_list, batch_size=32):
    """æ‰¹é‡ç¼–ç åˆ†å­"""
    all_vecs = []
    for i in range(0, len(mol_list), batch_size):
        batch = mol_list[i:i+batch_size]
        inputs = mol_tokenizer(batch, return_tensors="pt", padding=True,
                               truncation=True, max_length=128).to(DEVICE)
        with torch.no_grad():
            vecs = model.encode_molecule(inputs['input_ids'], inputs['attention_mask'])
        all_vecs.append(vecs)
    return torch.cat(all_vecs, dim=0)

# ============================================================================
# æ£€ç´¢åŠŸèƒ½
# ============================================================================
def search_molecules(protein_seq, top_k=TOP_K):
    """ç»™å®šè›‹ç™½è´¨ï¼Œæ£€ç´¢åˆ†å­"""
    if not protein_seq.strip():
        return "è¯·è¾“å…¥è›‹ç™½è´¨åºåˆ—"
    
    try:
        prot = protein_seq.strip().upper()
        query_vec = encode_protein(prot)
        scores = torch.matmul(query_vec, mol_vectors.T).squeeze().cpu().numpy()
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        results = []
        hit_positive = 0
        
        for rank, idx in enumerate(top_indices, 1):
            mol = mol_database[idx]
            sim = scores[idx]
            
            # æŸ¥æ‰¾è¯¥è›‹ç™½è´¨ä¸æ£€ç´¢åˆ°çš„åˆ†å­ä¹‹é—´çš„å®é™… pIC50
            info_str = ""
            key = (prot, mol)
            if key in pair_pic50:
                pic50 = pair_pic50[key]
                is_positive = pic50 >= POSITIVE_THRESHOLD
                if is_positive:
                    hit_positive += 1
                    info_str = f" | pIC50: **{pic50:.2f}** âœ“"
                else:
                    info_str = f" | pIC50: {pic50:.2f}"
            
            results.append(f"**{rank}.** `{mol}`  \nç›¸ä¼¼åº¦: {sim:.4f}{info_str}\n")
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        header = f"**Top-{top_k} æ£€ç´¢ç»“æœ** (å‘½ä¸­æ­£æ ·æœ¬: {hit_positive})\n\n"
        return header + "\n".join(results)
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

def search_proteins(smiles, top_k=TOP_K):
    """ç»™å®šåˆ†å­ï¼Œæ£€ç´¢è›‹ç™½è´¨"""
    if not smiles.strip():
        return "è¯·è¾“å…¥ SMILES"
    
    try:
        mol = smiles.strip()
        query_vec = encode_molecule(mol)
        scores = torch.matmul(query_vec, prot_vectors.T).squeeze().cpu().numpy()
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        results = []
        hit_positive = 0
        
        for rank, idx in enumerate(top_indices, 1):
            prot_seq = prot_database[idx]
            sim = scores[idx]
            
            display_seq = prot_seq[:60] + "..." if len(prot_seq) > 60 else prot_seq
            
            # æŸ¥æ‰¾æ£€ç´¢åˆ°çš„è›‹ç™½è´¨ä¸è¯¥åˆ†å­ä¹‹é—´çš„å®é™… pIC50
            info_str = ""
            key = (prot_seq, mol)
            if key in pair_pic50:
                pic50 = pair_pic50[key]
                is_positive = pic50 >= POSITIVE_THRESHOLD
                if is_positive:
                    hit_positive += 1
                    info_str = f" | pIC50: **{pic50:.2f}** âœ“"
                else:
                    info_str = f" | pIC50: {pic50:.2f}"
            
            results.append(f"**{rank}.** `{display_seq}`  \nç›¸ä¼¼åº¦: {sim:.4f}{info_str}\n")
        
        header = f"**Top-{top_k} æ£€ç´¢ç»“æœ** (å‘½ä¸­æ­£æ ·æœ¬: {hit_positive})\n\n"
        return header + "\n".join(results)
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

def compute_similarity(protein_seq, smiles):
    """è®¡ç®—å•å¯¹ç›¸ä¼¼åº¦"""
    if not protein_seq.strip() or not smiles.strip():
        return "è¯·è¾“å…¥è›‹ç™½è´¨åºåˆ—å’Œ SMILES"
    
    try:
        prot = protein_seq.strip().upper()
        mol = smiles.strip()
        prot_vec = encode_protein(prot)
        mol_vec = encode_molecule(mol)
        similarity = torch.matmul(prot_vec, mol_vec.T).item()
        
        # è§£é‡Šç›¸ä¼¼åº¦
        if similarity > 0.4:
            interpretation = "ğŸŸ¢ é«˜ç›¸ä¼¼åº¦ - å¯èƒ½å­˜åœ¨è¾ƒå¼ºçš„ç»“åˆäº²å’ŒåŠ›"
        elif similarity > 0.3:
            interpretation = "ğŸŸ¡ ä¸­ç­‰ç›¸ä¼¼åº¦ - å¯èƒ½å­˜åœ¨ä¸€å®šçš„ç»“åˆèƒ½åŠ›"
        elif similarity > 0.2:
            interpretation = "ğŸŸ  ä½ç›¸ä¼¼åº¦ - ç»“åˆå¯èƒ½æ€§è¾ƒä½"
        else:
            interpretation = "ğŸ”´ æä½ç›¸ä¼¼åº¦ - ä¸å¤ªå¯èƒ½æœ‰ç»“åˆ"
        
        # æŸ¥æ‰¾å®é™… pIC50ï¼ˆå¦‚æœæœ‰è®°å½•ï¼‰
        key = (prot, mol)
        ground_truth = ""
        if key in pair_pic50:
            pic50 = pair_pic50[key]
            is_positive = "âœ“ æ­£æ ·æœ¬" if pic50 >= POSITIVE_THRESHOLD else "âœ— éæ­£æ ·æœ¬"
            ground_truth = f"\n\n**å·²çŸ¥å®é™… pIC50: {pic50:.2f}** ({is_positive})"
        
        return f"## ç›¸ä¼¼åº¦å¾—åˆ†: {similarity:.4f}\n\n{interpretation}{ground_truth}"
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"

def get_random_example():
    """è·å–éšæœºç¤ºä¾‹ï¼ˆä»æ•°æ®åº“ä¸­é€‰æ‹©æœ‰æ­£æ ·æœ¬é…å¯¹çš„ï¼‰"""
    import random
    
    # æ‰¾æœ‰æ­£æ ·æœ¬çš„è›‹ç™½è´¨
    prots_with_pos = defaultdict(list)
    for (prot, mol), pic50 in pair_pic50.items():
        if pic50 >= POSITIVE_THRESHOLD:
            prots_with_pos[prot].append((mol, pic50))
    
    if not prots_with_pos:
        return EXAMPLE_PROTEIN, EXAMPLE_SMILES
    
    # éšæœºé€‰ä¸€ä¸ªè›‹ç™½è´¨
    prot = random.choice(list(prots_with_pos.keys()))
    # é€‰å®ƒ pIC50 æœ€é«˜çš„åˆ†å­
    mols = prots_with_pos[prot]
    mol, pic50 = max(mols, key=lambda x: x[1])
    
    return prot, mol

# ============================================================================
# Gradio ç•Œé¢
# ============================================================================
def create_demo():
    with gr.Blocks(title="è›‹ç™½è´¨-åˆ†å­åŒå‘æ£€ç´¢", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ§¬ è›‹ç™½è´¨-åˆ†å­åŒå‘æ£€ç´¢ç³»ç»Ÿ
        
        åŸºäºåŒå¡”å¯¹æ¯”å­¦ä¹ çš„æ£€ç´¢æ¨¡å‹ï¼ˆIC50 ç‰ˆæœ¬ï¼‰ï¼Œæ”¯æŒï¼š
        - **Protein â†’ Molecule**ï¼šç»™å®šé¶ç‚¹è›‹ç™½ï¼Œæ£€ç´¢å€™é€‰ç»“åˆåˆ†å­
        - **Molecule â†’ Protein**ï¼šç»™å®šå°åˆ†å­ï¼Œè¯†åˆ«æ½œåœ¨é¶ç‚¹è›‹ç™½
        - **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šè¯„ä¼°è›‹ç™½è´¨-åˆ†å­é…å¯¹çš„ç»“åˆå¯èƒ½æ€§
        
        > ğŸ’¡ æ­£æ ·æœ¬å®šä¹‰: pIC50 â‰¥ 7.0 (IC50 < 100nM)
        """)
        
        with gr.Tab("ğŸ”¬ è›‹ç™½è´¨ â†’ åˆ†å­"):
            gr.Markdown("è¾“å…¥è›‹ç™½è´¨åºåˆ—ï¼Œæ£€ç´¢å¯èƒ½ç»“åˆçš„å°åˆ†å­ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰")
            with gr.Row():
                with gr.Column():
                    prot_input = gr.Textbox(
                        label="è›‹ç™½è´¨åºåˆ—",
                        placeholder="è¾“å…¥æ°¨åŸºé…¸åºåˆ—",
                        lines=4,
                        value=EXAMPLE_PROTEIN
                    )
                    with gr.Row():
                        search_mol_btn = gr.Button("ğŸ” æ£€ç´¢åˆ†å­", variant="primary")
                        random_prot_btn = gr.Button("ğŸ² éšæœºç¤ºä¾‹")
                with gr.Column():
                    mol_output = gr.Markdown(label="æ£€ç´¢ç»“æœ")
            
            search_mol_btn.click(search_molecules, inputs=prot_input, outputs=mol_output)
            random_prot_btn.click(lambda: get_random_example()[0], outputs=prot_input)
        
        with gr.Tab("ğŸ’Š åˆ†å­ â†’ è›‹ç™½è´¨"):
            gr.Markdown("è¾“å…¥åˆ†å­ SMILESï¼Œæ£€ç´¢å¯èƒ½çš„é¶ç‚¹è›‹ç™½ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰")
            with gr.Row():
                with gr.Column():
                    mol_input = gr.Textbox(
                        label="åˆ†å­ SMILES",
                        placeholder="è¾“å…¥ SMILES",
                        lines=2,
                        value=EXAMPLE_SMILES
                    )
                    with gr.Row():
                        search_prot_btn = gr.Button("ğŸ” æ£€ç´¢è›‹ç™½è´¨", variant="primary")
                        random_mol_btn = gr.Button("ğŸ² éšæœºç¤ºä¾‹")
                with gr.Column():
                    prot_output = gr.Markdown(label="æ£€ç´¢ç»“æœ")
            
            search_prot_btn.click(search_proteins, inputs=mol_input, outputs=prot_output)
            random_mol_btn.click(lambda: get_random_example()[1], outputs=mol_input)
        
        with gr.Tab("âš¡ ç›¸ä¼¼åº¦è®¡ç®—"):
            gr.Markdown("è®¡ç®—å•å¯¹è›‹ç™½è´¨-åˆ†å­çš„ç›¸ä¼¼åº¦å¾—åˆ†")
            with gr.Row():
                with gr.Column():
                    pair_prot = gr.Textbox(label="è›‹ç™½è´¨åºåˆ—", lines=3, value=EXAMPLE_PROTEIN)
                    pair_mol = gr.Textbox(label="åˆ†å­ SMILES", lines=1, value=EXAMPLE_SMILES)
                    with gr.Row():
                        calc_btn = gr.Button("âš¡ è®¡ç®—ç›¸ä¼¼åº¦", variant="primary")
                        random_pair_btn = gr.Button("ğŸ² éšæœºé…å¯¹")
                with gr.Column():
                    sim_output = gr.Markdown()
            
            calc_btn.click(compute_similarity, inputs=[pair_prot, pair_mol], outputs=sim_output)
            random_pair_btn.click(get_random_example, outputs=[pair_prot, pair_mol])
        
        with gr.Tab("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡"):
            gr.Markdown(f"""
            ### æ£€ç´¢æ•°æ®åº“ä¿¡æ¯
            
            | é¡¹ç›® | æ•°é‡ |
            |------|------|
            | è›‹ç™½è´¨åº“ | {len(prot_database)} |
            | åˆ†å­åº“ | {len(mol_database)} |
            | å·²çŸ¥é…å¯¹ | {len(pair_pic50)} |
            | æ­£æ ·æœ¬é…å¯¹ | {sum(1 for v in pair_pic50.values() if v >= POSITIVE_THRESHOLD)} |
            
            **æ­£æ ·æœ¬é˜ˆå€¼**: pIC50 â‰¥ {POSITIVE_THRESHOLD}
            """)
        
        gr.Markdown("""
        ---
        **æ¨¡å‹ä¿¡æ¯**: SaProt (650M) + ChemBERTa | è®­ç»ƒæ•°æ®: BindingDB
        """)
    
    return demo

# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================
if __name__ == "__main__":
    load_model()
    demo = create_demo()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)
